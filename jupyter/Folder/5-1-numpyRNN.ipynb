{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "#     e_x = np.exp(x)\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def initialize_adam(parameters):\n",
    "    L = len(parameters)/2\n",
    "    v = {}\n",
    "    s = {}\n",
    "    for l in range(L):\n",
    "        v['dW'+str(l+1)] = np.zeros(parameters['W'+str(l+1)].shape)\n",
    "        v['db'+str(l+1)] = np.zeros(parameters['b'+str(l+1)].shape)\n",
    "        s['dW'+str(l+1)] = np.zeros(parameters['W'+str(l+1)].shape)\n",
    "        s['db'+str(l+1)] = np.zeros(parameters['b'+str(l+1)].shape)\n",
    "    return v,s\n",
    "\n",
    "def update_parameters_with_adam(parameters,grads,v,s,t,\n",
    "                                learning_rate=0.01,beta1=0.9,beta2=0.999,epsilon=1e-8):\n",
    "    # parameters['W'+str(l)] = W1\n",
    "    # grads['dW'+str(l)] = dW1\n",
    "    L = len(parameters)//2\n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v['dW'+str(l+1)] = beta1*v['dW'+str(l+1)]+(1-beta1)*grads['dW'+str(l+1)]\n",
    "        v['db'+str(l+1)] = beta1*v['db'+str(l+1)]+(1-beta1)*grads['db'+str(l+1)]\n",
    "        s['dW'+str(l+1)] = beta2*s['dW'+str(l+1)]+(1-beta2)*(grads['dW'+str(l+1)]**2)\n",
    "        s['db'+str(l+1)] = beta2*s['db'+str(l+1)]+(1-beta2)*(grads['db'+str(l+1)]**2)\n",
    "        \n",
    "        v_corrected['dW'+str(l+1)] = v['dW'+str(l+1)]/(1-beta1**t)\n",
    "        v_corrected['db'+str(l+1)] = v['db'+str(l+1)]/(1-beta1**t)\n",
    "        s_corrected['dW'+str(l+1)] = s['dW'+str(l+1)]/(1-beta2**t)\n",
    "        s_corrected['db'+str(l+1)] = s['db'+str(l+1)]/(1-beta2**t)\n",
    "        \n",
    "        parameters['W'+str(l+1)] = parameters['W'+str(l+1)]-learning_rate*v_corrected['dW'+str(l+1)]/np.sqrt(s['dW'+str(l+1)]+epsilon)\n",
    "        parameters['b'+str(l+1)] = parameters['b'+str(l+1)]-learning_rate*v_corrected['db'+str(l+1)]/np.sqrt(s['db'+str(l+1)]+epsilon)\n",
    "    return parameters, v, s\n",
    "\n",
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    Wax = parameters['Wax']\n",
    "    Waa = parameters['Waa']\n",
    "    ba = parameters['ba']\n",
    "    by = parameters['by']\n",
    "    \n",
    "    a_next = np.tanh(np.dot(Waa,a_prev) + np.dot(Waa, xt) + ba)\n",
    "    yt_pred = softmax(np.dot(Way, a_next) + by)\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "    return a_next, yt_pred, cache\n",
    "\n",
    "def rnn_forward(x, a0, parameters):\n",
    "    caches = []\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters['Wya'].shape\n",
    "    \n",
    "    a = np.zeros((n_a,m,T_x))\n",
    "    y_pred = np.zeros((n_y, m, T_x))\n",
    "    a_next = a0\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t],a_next,parameters)\n",
    "        a[:,:,t] = a_next\n",
    "        y_pred[:,:,t] = yt_pred\n",
    "        caches.append(cache)\n",
    "    caches = (caches, x)\n",
    "    return a, y_pred, caches\n",
    "\n",
    "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n",
    "    # weights matrix of the forget gate\n",
    "    Wf = parameters['Wf']\n",
    "    bf = parameters['bf']\n",
    "    # weights matrix og the update gate\n",
    "    Wi = parameters['Wi']\n",
    "    bi = parameters['bi']\n",
    "    # weights matrix of the first tanh\n",
    "    Wc = parameters['Wc']\n",
    "    bc = parameters['bc']\n",
    "    # weights matrix of the output gate\n",
    "    Wo = parameters['Wo']\n",
    "    bo = parameters['bo']\n",
    "    # weights matrix relating the hidden-state to the output\n",
    "    Wy = parameters['Wy']\n",
    "    by = parameters['by']\n",
    "    \n",
    "    n_x, m = xt.shape\n",
    "    n_y, n_a = Wy.shape\n",
    "    \n",
    "    concat = np.zeros((n_x+n_a, m))\n",
    "    concat[:n_a, :] = a_prev\n",
    "    concat[n_a:, :] = xt\n",
    "    \n",
    "    ft = sigmoid(np.dot(Wf, concat)+bf)\n",
    "    it = sigmoid(np.dot(Wi, concat)+bi)\n",
    "    cct = np.tanh(np.dot(Wc, concat)+bc)\n",
    "    c_next = ft*c_prev + it*cct\n",
    "    ot = sigmoid(np.dot(Wo, concat)+bo)\n",
    "    a_next = ot*np.tanh(c_next)\n",
    "    \n",
    "    yt_pred = softmax(np.dot(Wy, a_next)+by)\n",
    "    caches = (a_next,c_next,a_prev,c_prev,ft,it,cct,ot,xt,parameters)\n",
    "    return a_next, c_next, yt_pred, cache\n",
    "\n",
    "deff lstm_forward(x, a0, parameters):\n",
    "    caches = []\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters['Wy'].shape\n",
    "    \n",
    "    a = np.zeros((n_a, m, T_X))\n",
    "    c = np.zeros((n_a, m, T_x))\n",
    "    y = np.zeros((n_y, m, T_x))\n",
    "    \n",
    "    a_next = a0\n",
    "    c_next = np.zeros((n_a, m))\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        a_next,c_next,yt, cache = lstm_cell_forward(x[:,:,t],a_next,c_next,parameters)\n",
    "        a[:,:,t] = a_next\n",
    "        y[:,:,t] = yt\n",
    "        c[:,:,t] = c_next\n",
    "        cachess.append(cache)\n",
    "    caches = (caches, x)\n",
    "    return a,y,c,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
