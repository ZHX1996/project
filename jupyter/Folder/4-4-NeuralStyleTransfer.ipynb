{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0 :\n",
      "total cost= 4946347500.0\n",
      "content cost= 7864.7256\n",
      "style cost= 123656720.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from Imageio import Image\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class CONFIG:\n",
    "    ORIGIN_PATH = 'F:/houseworkData/neuralStyleTransfer/'\n",
    "    IMAGE_WIDTH = 400\n",
    "    IMAGE_HEIGHT = 300\n",
    "    COLOR_CHANNELS = 3\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([123.68,116.779,103.939]).reshape((1,1,1,3))\n",
    "    VGG_IMAGE = ORIGIN_PATH + 'imagenet-vgg-verydeep-19.mat'\n",
    "    STYLE_IMAGE = ORIGIN_PATH + 'stone_style.jpg'\n",
    "    CONTENT_IMAGE = ORIGIN_PATH + 'content300.jpg'\n",
    "    OUTPUT_DIR = ORIGIN_PATH\n",
    "    \n",
    "STYLE_LAYERS = [\n",
    "        ('conv1_1',0.2),\n",
    "        ('conv2_1',0.2),\n",
    "        ('conv3_1',0.2),\n",
    "        ('conv4_1',0.2),\n",
    "        ('conv5_1',0.2)\n",
    "    ]\n",
    "    \n",
    "def load_vgg_model(path):\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "        wb = vgg_layers[0][layer][0][0][2]\n",
    "        W = wb[0][0]\n",
    "        b = wb[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "    \n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b,(b.size)))\n",
    "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1,1,1,1],padding='SAME') + b\n",
    "    \n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer,layer,layer_name))\n",
    "    \n",
    "    def _avgpool(prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    graph = {}\n",
    "    graph['input'] = tf.Variable(np.zeros((1,CONFIG.IMAGE_HEIGHT,CONFIG.IMAGE_WIDTH,CONFIG.COLOR_CHANNELS)), dtype='float32')\n",
    "    graph['conv1_1'] = _conv2d_relu(graph['input'],0,'conv1_1')\n",
    "    graph['conv1_2']=_conv2d_relu(graph['conv1_1'],2,'conv1_2')\n",
    "    graph['avgpool1']=_avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']=_conv2d_relu(graph['avgpool1'],5,'conv2_1')\n",
    "    graph['conv2_2']=_conv2d_relu(graph['conv2_1'],7,'conv2_2')\n",
    "    graph['avgpool2']=_avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']=_conv2d_relu(graph['avgpool2'],10,'conv3_1')\n",
    "    graph['conv3_2']=_conv2d_relu(graph['conv3_1'],12,'conv3_2')\n",
    "    graph['conv3_3']=_conv2d_relu(graph['conv3_2'],14,'conv3_3')\n",
    "    graph['conv3_4']=_conv2d_relu(graph['conv3_3'],16,'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']=_conv2d_relu(graph['avgpool3'],19,'conv4_1')\n",
    "    graph['conv4_2']=_conv2d_relu(graph['conv4_1'],21,'conv4_2')\n",
    "    graph['conv4_3']=_conv2d_relu(graph['conv4_2'],23,'conv4_3')\n",
    "    graph['conv4_4']=_conv2d_relu(graph['conv4_3'],25,'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']=_conv2d_relu(graph['avgpool4'],28,'conv5_1')\n",
    "    graph['conv5_2']=_conv2d_relu(graph['conv5_1'],30,'conv5_2')\n",
    "    graph['conv5_3']=_conv2d_relu(graph['conv5_2'],32,'conv5_3')\n",
    "    graph['conv5_4']=_conv2d_relu(graph['conv5_3'],34,'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph\n",
    "\n",
    "def generate_noise_image(content_image,noise_ratio=CONFIG.NOISE_RATIO):\n",
    "    noise_image = np.random.uniform(-20,20,(1,CONFIG.IMAGE_HEIGHT,CONFIG.IMAGE_WIDTH,CONFIG.COLOR_CHANNELS)).astype('float32')\n",
    "    input_image = noise_image*noise_ratio+content_image*(1-noise_ratio)\n",
    "    return input_image\n",
    "\n",
    "def reshape_and_normalize_image(image):\n",
    "    image = np.reshape(image,((1,)+image.shape))\n",
    "    image = image - CONFIG.MEANS\n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image + CONFIG.MEANS\n",
    "    image = np.clip(image[0],0,255).astype('uint8')\n",
    "    imageio.imsave(path, image)\n",
    "    \n",
    "# content cost\n",
    "def compute_content_cost(a_C, a_G):\n",
    "    m,n_H,n_W,n_C = a_G.get_shape().as_list()\n",
    "    a_C_unrolled = tf.reshape(a_C,[n_H*n_W,n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G,[n_H*n_W,n_C])\n",
    "#     print(m,n_H,n_W,n_C)\n",
    "#     print(a_G.eval().shape)\n",
    "#     print(a_G_unrolled.eval().shape)\n",
    "    J_content = 1./(4*n_H*n_W*n_C)*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))\n",
    "    return J_content\n",
    "\n",
    "# style matrix\n",
    "def gram_matrix(A):\n",
    "    GA = tf.matmul(A, tf.transpose(A))\n",
    "    return GA\n",
    "\n",
    "# style cost\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W,n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W,n_C]))\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "    J_style_layer = 1./(4*n_C*n_C*n_H*n_W*n_H*n_W)*tf.reduce_sum(tf.square(tf.subtract(GS,GG)))\n",
    "    return J_style_layer\n",
    "    \n",
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    J_style = 0\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        out = model[layer_name]\n",
    "        a_S = sess.run(out)\n",
    "        a_G = out\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "        J_style += coeff * J_style_layer\n",
    "    return J_style\n",
    "\n",
    "def total_cost(J_content, J_style, alpha=10, beta=40):\n",
    "    J = alpha*J_content + beta*J_style\n",
    "    return J\n",
    "    \n",
    "def model_nn(sess, input_image, num_iterations=200):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        sess.run(train_step)\n",
    "        generated_image = sess.run(model['input'])\n",
    "        \n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print('iteration ', i, ':')\n",
    "            print('total cost=', Jt)\n",
    "            print('content cost=', Jc)\n",
    "            print('style cost=', Js)\n",
    "            save_image(CONFIG.ORIGIN_PATH+str(i)+'.png', generated_image)\n",
    "    save_image(CONFIG.ORIGIN_PATH+'last.jpg', generated_image)\n",
    "    \n",
    "\n",
    "model = load_vgg_model(CONFIG.VGG_IMAGE)\n",
    "#     print(model)\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "content_image = imageio.imread(CONFIG.ORIGIN_PATH+'louvre_small.jpg')\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "\n",
    "style_image = imageio.imread(CONFIG.ORIGIN_PATH+'monet.jpg')\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "generated_image = generate_noise_image(content_image)\n",
    "#     imshow(generated_image[0])\n",
    "\n",
    "sess.run(model['input'].assign(content_image))\n",
    "out = model['conv4_2']\n",
    "a_C = sess.run(out)\n",
    "a_G = out\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "sess.run(model['input'].assign(style_image))\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "\n",
    "J = total_cost(J_content, J_style, 10, 40)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(J)\n",
    "\n",
    "model_nn(sess, generated_image)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
