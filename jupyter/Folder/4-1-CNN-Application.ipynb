{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  loss:  0.052340258 [[0.41855884 0.60662246]] [-0.23592322]\n",
      "step:  100  loss:  2.6484398e-07 [[0.1010092  0.20141523]] [0.29871234]\n",
      "step:  200  loss:  2.2967494e-12 [[0.10000296 0.20000418]] [0.2999962]\n",
      "step:  300  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  400  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  500  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  600  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  700  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  800  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n",
      "step:  900  loss:  1.731948e-15 [[0.10000008 0.20000012]] [0.2999999]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(2,100).astype(\"float32\")\n",
    "Y = np.dot([0.1,0.2],X)+0.3\n",
    "bias = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1,2],-1.0,1.0))\n",
    "y = tf.add(tf.matmul(W,X), bias)\n",
    "loss = tf.reduce_mean(tf.square(y-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for step in range(0, 1000):\n",
    "    sess.run(train)\n",
    "    if step%100==0:\n",
    "        print(\"step: \" , step, \" loss: \" , sess.run(loss), sess.run(W), sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.921825\n",
      "Cost after epoch 5: 1.904152\n",
      "Cost after epoch 10: 1.904319\n",
      "Cost after epoch 15: 1.904581\n",
      "Cost after epoch 20: 1.904157\n",
      "Cost after epoch 25: 1.904098\n",
      "Cost after epoch 30: 1.752994\n",
      "Cost after epoch 35: 1.641618\n",
      "Cost after epoch 40: 1.591664\n",
      "Cost after epoch 45: 1.589229\n",
      "Cost after epoch 50: 1.477437\n",
      "Cost after epoch 55: 1.302648\n",
      "Cost after epoch 60: 1.193441\n",
      "Cost after epoch 65: 1.171850\n",
      "Cost after epoch 70: 1.080340\n",
      "Cost after epoch 75: 1.069238\n",
      "Cost after epoch 80: 1.021812\n",
      "Cost after epoch 85: 1.006125\n",
      "Cost after epoch 90: 0.964422\n",
      "Cost after epoch 95: 0.936594\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "train accuracy:  0.68796295\n",
      "test accuracy:  0.55833334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import math\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant')\n",
    "    return X_pad\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    '''\n",
    "    a_slice_prev:slice of input data of shape(f,f,n_C_prev)\n",
    "    W: shape (f,f,n_C_prev)\n",
    "    b: shape (1,1,1)\n",
    "    '''\n",
    "    s = a_slice_prev * W\n",
    "    Z = np.sum(s)\n",
    "    Z = Z+b\n",
    "    return Z\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparams):\n",
    "    (m,n_H_prev,n_W_prev,n_C_prev) = A_prev.shape\n",
    "    (f,f,n_c_prev,n_C) = W.shape\n",
    "    stride = hparams['stride']\n",
    "    pad = hparams['pad']\n",
    "    \n",
    "    n_H = int((n_H_prev+2*pad-f)/stride+1)\n",
    "    n_W = int((n_W_prev+2*pad-f)/stride+1)\n",
    "    \n",
    "    Z = np.zeros((m,n_H,n_W,n_C))\n",
    "    \n",
    "    A_prev_pad = zero_pad(A_prev,pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i,:,:,:]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    vert_start = stride*h\n",
    "                    vert_end = vert_start+f\n",
    "                    horiz_start = stride*w\n",
    "                    horiz_end = horiz_start+f\n",
    "                    \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    Z[i,h,w,c] = conv_single_step(a_slice_prev,W[:,:,:,c],b[:,:,:,c])\n",
    "    cache = (A_prev,W,b,hparams)\n",
    "    return Z,cache\n",
    "\n",
    "def pool_forward(A_prev,hparams,mode='max'):\n",
    "    (m,n_H_prev,n_W_prev,n_C_prev) = A_prev.shape\n",
    "    f = hparams['f']\n",
    "    stride = hparams['stride']\n",
    "    \n",
    "    n_H = int((n_H_prev-f)/stride + 1)\n",
    "    n_W = int((n_W_prev-f)/stride + 1)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    A = np.zeros((m,n_H,n_W,n_C))\n",
    "    for i in range(m):\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_prev_slice = A_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    if mode == \"max\":\n",
    "                        A[i,h,w,c] = np.max(a_prev_slice)\n",
    "                    elif mode == 'average':\n",
    "                        A[i,h,w,c] = np.mean(a_prev_slice)\n",
    "    cache = (A_prev, hparams)\n",
    "    return A, cache\n",
    "\n",
    "def conv_backward(dZ, cache):\n",
    "    (A_prev,W,b,hparams) = cache\n",
    "    (m,n_H_prev,n_W_prev,n_C_prev) = A_prev.shape\n",
    "    (f,f,n_C_prev,n_C) = W.shape\n",
    "    \n",
    "    stride = hparams['stride']\n",
    "    pad = hparams['pad']\n",
    "    \n",
    "    (m,n_H,n_W,n_C) = dZ.shape\n",
    "    \n",
    "    dA_prev = np.zeros((m,n_H_prev,n_W_prev,n_C_prev))\n",
    "    dW = np.zeros((f,f,n_C_prev,n_C))\n",
    "    db = np.zeros((1,1,1,n_C))\n",
    "    \n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i,:,:,:]\n",
    "        da_prev_pad = dA_prev_pad[i,:,:,:]\n",
    "        \n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    da_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:] += W[:,:,:,C]*dZ[i,h,w,c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i,h,w,c]\n",
    "                    db[:,:,:,c] += dZ[i,h,w,c]\n",
    "        dA_prev[i,:,:,:] = da_prev_pad[pad:-pad,pad:-pad,:]\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def create_mask_from_window(x):\n",
    "    mask = (x == np.max(x))\n",
    "    return mask\n",
    "\n",
    "def distribute_value(dz, shape):\n",
    "    (n_H, n_W) = shape\n",
    "    average = dz /(n_H*n_W)\n",
    "    a = average * np.ones(shape)\n",
    "    return a\n",
    "\n",
    "def pool_backward(dA, cache, mode='max'):\n",
    "    (A_prev, hparams) = cache\n",
    "    stride = hparams[\"stride\"]\n",
    "    f = hparams['f']\n",
    "\n",
    "    m,n_H_prev,n_W_prev,n_C_prev = A_prev.shape\n",
    "    m,n_H,n_W,n_C = dA.shape\n",
    "\n",
    "    dA_prev = np.zeros(np.shape(A_prev))\n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i,:,:,:]\n",
    "\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    if mode == 'max':\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        dA_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]+=np.multiply(mask,dA[i,h,w,c])\n",
    "                    elif mode == 'average':\n",
    "                        da = dA[i,h,w,c]\n",
    "                        shape = (f,f)\n",
    "                        dA_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]+=distribute_value(da, shape)\n",
    "    return dA_prev\n",
    "\n",
    "# use tensorflow\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('E://project/data/tensorflow_tutorial_train_signs.h5', 'r')\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "    test_dataset = h5py.File('E://project/data/tensorflow_tutorial_test_signs.h5', 'r')\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "\n",
    "    classes = np.array(test_dataset['list_classes'][:])\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1,train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1,test_set_y_orig.shape[0]))\n",
    "    return train_set_x_orig,train_set_y_orig,test_set_x_orig,test_set_y_orig,classes\n",
    "\n",
    "def convert_to_one_hot(Y,C):\n",
    "    return np.eye(C)[Y.reshape(-1)].T\n",
    "\n",
    "def process_dataset(X_train_orig, Y_train_orig, X_test_orig, Y_test_orig):\n",
    "    X_train = X_train_orig/255\n",
    "    X_test = X_test_orig/255\n",
    "    Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "    Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_y])\n",
    "    return X, Y\n",
    "\n",
    "def init_params():\n",
    "    tf.set_random_seed(1)\n",
    "    W1 = tf.get_variable(\"W1\",[4,4,3,8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\",[2,2,8,16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    params = {\"W1\":W1, \"W2\":W2}\n",
    "    return params\n",
    "\n",
    "def forward_propagation(X, params):\n",
    "    W1 = params[\"W1\"]\n",
    "    W2 = params[\"W2\"]\n",
    "     \n",
    "    # strides=[1,s,s,1]  ksize=[1,f,f,1]\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding=\"SAME\")\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding=\"SAME\")\n",
    "    # into a 1D vector while maintaining the batch_size\n",
    "    # returns a flattened tensor with shape [batch_size,k]\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    # without an non-linear activation function\n",
    "    # 5 neurons in output layers\n",
    "    # hint:one of the arguments should be \"activation_fn=None\"\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 6, activation_fn = None)\n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))\n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.0089,\n",
    "         num_epoches=100, minibatch_size=64, print_cost=True):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "    costs = []\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    \n",
    "    params = init_params()\n",
    "    Z3 = forward_propagation(X, params)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epoches):\n",
    "            minibatch_cost = 0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost/num_minibatches\n",
    "                \n",
    "            if print_cost and epoch%5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost and epoch%1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iteration(per ten)')\n",
    "        plt.title(\"learning rate = \" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X:X_train, Y:Y_train})\n",
    "        test_accuracy = accuracy.eval({X:X_test, Y:Y_test})\n",
    "        print(\"train accuracy: \", train_accuracy)\n",
    "        print(\"test accuracy: \", test_accuracy)\n",
    "        return train_accuracy, test_accuracy, params\n",
    "    \n",
    "# def random_mini_batches(X,Y,mini_batch_size=64,seed=0):\n",
    "#     m = X.shape[1]\n",
    "#     mini_batches = []\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "#     permutation = list(np.random.permutation(m))\n",
    "#     shuffled_X = X[:,permutation]\n",
    "#     print(Y.shape)\n",
    "#     print(permutation)\n",
    "#     shuffled_Y = Y[:,permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "#     num_complete_minibatches= math.floor(m/mini_batch_size)\n",
    "#     for k in range(0, num_complete_minibatches):\n",
    "#         mini_batch_X = shuffled_X[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "#         mini_batch_Y = shuffled_Y[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "#         mini_batches.append((mini_batch_X,mini_batch_Y))\n",
    "#     if m%mini_batch_size!=0:\n",
    "#         mini_batch_X = shuffled_X[:,num_complete_minibatches*mini_batch_size:m]\n",
    "#         mini_batch_Y = shuffled_Y[:,num_complete_minibatches*mini_batch_size:m]\n",
    "#         mini_batches.append((mini_batch_X,mini_batch_Y))\n",
    "#     return mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    m = X.shape[0]                 \n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    return mini_batches\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "#     index = 6\n",
    "#     plt.imshow(X_train_orig[index])\n",
    "#     print(\"y=\"+str(np.squeeze(Y_train_orig[:,index])))\n",
    "    X_train, Y_train, X_test, Y_test = process_dataset(X_train_orig, Y_train_orig, X_test_orig, Y_test_orig)\n",
    "    _,_,params = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
