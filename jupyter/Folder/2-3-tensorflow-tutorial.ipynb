{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "# from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('C://Users/ZHX/Desktop/train_signs.h5', 'r')\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "    test_dataset = h5py.File('C://Users/ZHX/Desktop/test_signs.h5', 'r')\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "\n",
    "    classes = np.array(test_dataset['list_classes'][:])\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1,train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1,test_set_y_orig.shape[0]))\n",
    "    return train_set_x_orig,train_set_y_orig,test_set_x_orig,test_set_y_orig,classes\n",
    "\n",
    "def random_mini_batches(X,Y,mini_batch_size=64,seed=0):\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:,permutation]\n",
    "    shuffled_Y = Y[:,permutation].reshape((Y.shape[0],m))\n",
    "    num_complete_minibatches= math.floor(m/mini_batch_size)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batches.append((mini_batch_X,mini_batch_Y))\n",
    "    if m%mini_batch_size!=0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:m]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches*mini_batch_size:m]\n",
    "        mini_batches.append((mini_batch_X,mini_batch_Y))\n",
    "    return mini_batches\n",
    "\n",
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "def forward_propagation_for_predict(X, params):\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    W3 = params['W3']\n",
    "    b3 = params['b3']\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
    "    return Z3\n",
    "\n",
    "def predict(X, params):\n",
    "    W1 = tf.convert_to_tensor(params['W1'])\n",
    "    b1 = tf.convert_to_tensor(params['b1'])\n",
    "    W2 = tf.convert_to_tensor(params['W2'])\n",
    "    b2 = tf.convert_to_tensor(params['b2'])\n",
    "    W3 = tf.convert_to_tensor(params['W3'])\n",
    "    b3 = tf.convert_to_tensor(params['b3'])\n",
    "\n",
    "    params = {'W1':W1,'b1':b1,'W2':W2,'b2':b2,'W3':W3,'b3':b3}\n",
    "    x = tf.placeholder(\"float\",[12288,1])\n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict={x: X})\n",
    "    return prediction\n",
    "\n",
    "def linear_function():\n",
    "    np.random.seed(1)\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4,1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    sess.close()\n",
    "    return result\n",
    "\n",
    "def sigmoid(z):\n",
    "    x = tf.placeholder(tf.float32, name=\"x\")\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(sigmoid, feed_dict={x:z})\n",
    "    return result\n",
    "\n",
    "def cost(logits, labels):\n",
    "    z = tf.placeholder(tf.float32,  name='z')\n",
    "    y = tf.placeholder(tf.float32, name='y')\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "    with tf.Session() as sess:\n",
    "        cost = sess.run(cost, feed_dict={z:logits, y:labels})\n",
    "    return cost\n",
    "\n",
    "def one_hot_to_matrix(labels, C):\n",
    "    C = tf.constant(value=C, name='C')\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    return one_hot\n",
    "\n",
    "def ones(shape):\n",
    "    ones = tf.ones(shape)\n",
    "    sess = tf.Session()\n",
    "    ones = sess.run(ones)\n",
    "    sess.close()\n",
    "    return ones\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "    index = 0\n",
    "    plt.show(X_train_orig[index])\n",
    "    print(\"y=\"+str(np.squeeze(Y_train_orig[:,index])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
